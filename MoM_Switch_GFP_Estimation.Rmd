---
title: "GFP fluorescence estimation"
author: Thomas Julou
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

```{r eval=FALSE}
# shortcut when rerunning the analysis

if (use_eriks_params)
  autofluo_predict <- function(.h) .h * 422.8
myframes <- myframes %>%
    mutate(fluogfp_amplitude = fluo_amplitude - autofluo_predict(length_um))

fp_per_oligomers <- 4 # lacZ is tetrameric
if (use_eriks_params)
  fp_per_dn <- 0.0361 * fp_per_oligomers
myframes <- myframes %>%
  # convert to gfp units (after subtracting autofluorescence)
  mutate(gfp_nb = fluogfp_amplitude * fp_per_dn)

```


## Autofluorescence estimation

Let's look at how autofluorescence (measured as the fluorescence of MG1655 cells without GFP) correlates with cell length.

```{r autofluo}
ggplot(data=filter(myframes, condition=='mg1655') %>% filter(!discard_top)) + 
  geom_point(aes(length_um, fluo_amplitude), size=1, alpha=.2, position=position_jitter(width=1e-2)) + 
  geom_smooth(aes(length_um, fluo_amplitude, col='y=ax'), method='lm', formula=y~x-1,
              data=filter(myframes, condition=='mg1655') %>% filter(!discard_top, length_um>1.7, length_um<3.4))# +
  # xlim(0,6) + ylim(0, 3000)

ggplot(data=filter(filter(myframes, condition=='mg1655'), !discard_top), aes(length_um, fluo_amplitude)) + 
  geom_point(size=1, alpha=.2, position=position_jitter(width=1e-2)) + 
  geom_smooth(method='lm', col='red', formula=y~x-1, fullrange=TRUE,
              data=filter(filter(myframes, condition=='mg1655'), !discard_top, length_um>1.7, length_um<3.4))+
  labs(x='cell length (µm)', y='total fluorescence (AU)') +
  xlim(0,5) + ylim(0, 3000)
# ggsave('plots/mg_autofluo_length.pdf', width=5, height=3)

```

Let's check visually that fluctuations for a given cell correlate with its length (rather than having some cells systematically high or low). Then, we look at cells with high autofluorescence values: we checked manually for some of these that they exhibit a hot pixel (contributing the size-independent "autofluorescence").

```{r}
# sample cell trace
ns <- 6
ggplot(data=filter(myframes, condition=='mg1655') %>% 
         filter(!discard_top, pos==0,  gl==14) %>% 
         filter(cell %in% unique(cell)[sample(1:40, ns)])) + 
  # geom_abline(slope=mean_autofluo$slope0) +
  geom_smooth(aes(length_um, fluo_amplitude), method='lm', col='black', formula=y~x-1, fullrange=TRUE,
              data=filter(myframes, condition=='mg1655', !discard_top, length_um>1.7, length_um<3.4))+
  geom_path(aes(length_um, fluo_amplitude, col=cell), alpha=.5) + 
  xlim(1,4) + ylim(0, 3000)

# traces of outlier cells
filter(myframes, condition=='mg1655') %>% 
  filter(!discard_top, fluo_amplitude>2500, length_um<4) %>%
  ungroup %>% select(cell) %>% distinct %>% 
  semi_join(myframes, .) %>% ungroup %>% filter(!discard_top) %>% 
  ggplot(aes(length_um, fluo_amplitude)) + 
  # geom_abline(slope=mean_autofluo$slope0) +
  geom_smooth(method='lm', col='black', formula=y~x-1, fullrange=TRUE,
              data=filter(myframes, condition=='mg1655', !discard_top, length_um>1.7, length_um<3.4))+
  geom_path(aes(col=cell), alpha=.5) + 
  xlim(1,4) + ylim(0, 3000)

```


We estimate the slope of each cell that is not filamenting (between 1.7 and 3.4µm) and that is observed over 5 frames or more.
These slopes display a strong negative correlation with the intercepts. Cells with non-zero intercepts might correspond to cells with hot/dead pixels. Overall, the default intercept is not zero (does this correspond to the sum of non-zero values of pixels in the dark?).

```{r}
nframes_autofluo <- 5
mg_autofluo <- filter(myframes, condition=='mg1655') %>% 
  filter(!discard_top, !discard_start, length_um>1.7, length_um<3.4) %>%
  group_by(date, pos, gl, id) %>%
  mutate(npoints=n()) %>% filter(npoints>=nframes_autofluo) %>%
  do(mod0=lm(fluo_amplitude~length_um-1, data=.), mod=lm(fluo_amplitude~length_um, data=.)) %>%
  mutate(intercept=coef(mod)[1], slope=coef(mod)[2], slope.sd=summary(mod)$coeff[2, 2], 
         slope0=coef(mod0)[1], slope0.sd=summary(mod0)$coeff[1, 2],
         r2=summary(mod)$r.squared, r2_0=summary(mod0)$r.squared)

ggplot(mg_autofluo, aes(intercept, slope)) +
  geom_errorbar(aes(ymin=slope-slope.sd, ymax=slope+slope.sd), alpha=0.2) +
  geom_point(alpha=0.2) +
  geom_vline(xintercept=c(-500, 900), col='red')

qplot(intercept, data=mg_autofluo) +
  geom_vline(xintercept=c(-500, 900), col='red')

```

Overall the fit is much better for a model constrained through the origin?! This yields a narrower distribution of slopes. We use this model and estimate the average slope (using errors) to predict the autofluorescence at a given cell length.

```{r}
ggplot(filter(mg_autofluo, between(intercept, -500, 900))) +
  stat_ecdf(aes(r2_0, col='Y=aX')) +
  stat_ecdf(aes(r2, col='Y=aX+b')) +
  labs(x='r2', y='cumulative', col='model')

mean_autofluo <- mg_autofluo %>% ungroup %>%
  summarise(slope0=sqrt( sum(slope0^2/slope0.sd^2) / sum(1/slope0.sd^2) ), 
            slope0.sd=1 / sqrt(sum(1/slope0.sd^2)))

ggplot(filter(mg_autofluo, between(intercept, -500, 900))) +
  # geom_step_hist(aes(slope0, col='Y=aX')) +
  # geom_step_hist(aes(slope, col='Y=aX+b')) +
  stat_ecdf(aes(slope0, col='Y=aX')) +
  stat_ecdf(aes(slope, col='Y=aX+b')) +
  geom_vline(aes(xintercept=slope0, col='Y=aX'), data=mean_autofluo, lty='dashed') +
  labs(x='slope (DN/µm)', y='cumulative', col='model')

autofluo_predict <- function(.h) .h * mean_autofluo$slope0
if (use_eriks_params)
  autofluo_predict <- function(.h) .h * 422.8
myframes <- myframes %>%
    mutate(fluogfp_amplitude = fluo_amplitude - autofluo_predict(length_um))

```


The autofluorescence concentration is noticeably impacted by the extracellular conditions. For instance, it increases dramatically when the environment is switched to lactose. Are the intial and post-switch decreases due to bleaching?

```{r}
filter(myframes, condition=='mg1655') %>% 
  filter(!discard_top) %>% 
  head(1e4) %>% 
ggplot(aes(time_sec, fluo_amplitude/length_um)) + 
  geom_rect(aes(x=1, y=1, xmin=t_start, xmax=t_end, ymin=-Inf, ymax=Inf, fill=medium), alpha=.1, data=filter(condition_ts, condition=='mg1655')) + # draws one rectangle per data line
  geom_hline(yintercept=mean_autofluo$slope0, lty='dashed') +
  geom_point(alpha=.2, size=1) +
  geom_smooth(method='loess', span=.05, se=FALSE) +
  scale_x_hours() +
  ylim(0, 1e3) +
  labs(x='time (h)', y='autofluorescence \nconcentration (DN/µm)', fill='condition')
# ggsave('plots/mg_autofluoconc_time.pdf', width=6, height=3)

```



## Photobleaching estimation

### Rationale
We assume that fluorescent proteins (FPs) are present in two states: unbleached (U) and bleached (B). FPs are produced as unbleached at a rate $\alpha$. Unbleached proteins are bleached at a rate $\beta$ and all proteins are degraded at a rate $\delta$. The total fluorescence measured in a cell is proportional to U. \
NB: the assumption that the probablity of degradation is constant with time is not realistic, contrary to the assumption of a constant rate of bleaching. \
![bleaching process](material/bleachingProcess.png)

When FPs are produced (lactose): $\frac{dU}{dt} = \alpha - (\beta + \delta) U$ \
When no FPs are produced (glucose): $\frac{dU}{dt} = -(\beta + \delta) U$ \

When no FPs are produced, the total fluorescence decreases rapidly (though the total number of FPs is expected to be constant). This is a direct observation of photobleaching and protein degradation and we can estimate $\beta + \delta$ as the decay rate of U. We also use this regime to estimate the conversion factor between camera units and FP units. In this case, the partitioning can be better estimated by extrapolating the mother and daughters fluorescence at division between the 2 adjacent time points (based on the exponential decay model).

When FPs are produced, $U(t+dt) = U(t) - (\beta + \delta) dt U(t) + \alpha(t) dt (\beta + \delta) dt$. \
$\alpha = (U(t+dt) - U(t) + (\beta + \delta) dt U(t)) / (\beta + \delta) dt^2$
Hence knowing the bleaching and degradation rate, one can estimate the instantaneous production rate \alpha(t)
NB: means that average production rate over the cell cycle not taking bleaching and degradation into account are correct up to a constant.


### Estimation

We focus on estimating $\beta + \delta$ and aim at extrapolating the mother and daughters fluorescence at division between the 2 adjacent time points.

Let's first look at fluorescence decay for cells in a given lane. The slopes are steeper for more fluorescent cells, which suggests proportional decay (as expected). This is nicely confirmed by constant slope in log scale.

```{r}
# ts <- filter(condition_ts, condition=='switch_04h', medium=='glucose')$t_start
# te <- filter(condition_ts, condition=='switch_04h', medium=='glucose')$t_end

p_decayGFP_lin <- myframes %>% 
  filter(!discard_start, !discard_top, end_type=='div') %>% 
  # filter(condition=='switch_04h') %>% 
  filter(medium=='glucose', m_cycle>1, time_sec>m_start+30*60) %>%
  # ungroup %>% filter(gl_id %in% nth(unique(gl_id), 11)) %>% # workaround a dplyr 0.5 bug
  ungroup %>% filter(gl_id %in% (unique(gl_id)[[11]]) ) %>%
  group_by(date, pos, gl, id) %>% 
  filter(m_cycle==first(m_cycle)) %>% # discard cells spanning several switches
  filter(mean(fluogfp_amplitude) > mean(autofluo_predict(length_um))) %>% # discard cells with fluo lower than avg autofluo
  filter(n() > 10) %>% # discard cells with less than 10 points
  mutate(time_sec_ini=first(time_sec)) %>% 
  ggplot(aes(time_sec-time_sec_ini, fluogfp_amplitude, col=cell)) +
  geom_path(alpha=0.6) +
  expand_limits(y=0) +
  scale_colour_periodic_brewer(guide='none') +
  scale_x_hours(0.5, name='time after switch / birth (h)') +
  labs(y='GFP level (AU)') +
  scale_y_log10() +
  theme_classic()
  
p_decayGFP_exp <- p_decayGFP_lin +
  scale_y_continuous(trans='log10', breaks=c(5e3, 1e4, 2e4, 4e4))

bleaching_fits <- myframes %>% 
  filter(!discard_start, !discard_top, end_type=='div') %>% 
  # filter(condition=='switch_04h') %>% 
  filter(medium=='glucose', m_cycle>1, time_sec>m_start+30*60) %>%
  # # ungroup %>% filter(gl_id %in% nth(unique(gl_id), 11)) %>% # workaround a dplyr 0.5 bug
  # ungroup %>% filter(gl_id %in% (unique(gl_id)[[11]]) ) %>%
  # group_by(condition, date, pos, gl, id) %>%
  partition(condition, date, pos, gl, id,
            cluster=mycluster %>% cluster_assign_func(autofluo_predict)) %>%
  filter(m_cycle==first(m_cycle)) %>% # discard cells spanning several switches
  filter(mean(fluogfp_amplitude) > mean(autofluo_predict(length_um))) %>% # discard cells with fluo lower than avg autofluo
  mutate(npoints=sum(fluogfp_amplitude>0)) %>%
  filter(npoints>10) %>%
  do(npoints=first(.$npoints), time_sec_ini=first(.$time_sec),
     fluogfp_amplitude_ini=first(.$fluogfp_amplitude),
     mod_lin=lm(fluogfp_amplitude~time_sec, data=.), 
     mod_exp=lm(log(fluogfp_amplitude)~time_sec, data=.)) %>%
  mutate(npoints=unlist(npoints), time_sec_ini=unlist(time_sec_ini),
         fluogfp_amplitude_ini=unlist(fluogfp_amplitude_ini),
         slope=summary(mod_lin)$coeff[2], r2=summary(mod_lin)$r.squared,
         slope.sd=summary(mod_lin)$coeff[2, 2],
         exp_slope=summary(mod_exp)$coeff[2], exp_r2=summary(mod_exp)$r.squared,
         exp_slope.sd=summary(mod_exp)$coeff[2, 2]) %>%
  collect() %>% 
  ungroup %>%
  mutate(cell=paste(date, pos, gl, id, sep='.'))

```

We fit the decay (accounting for the cell autofluorescence) for each cell observed on 10 frames or more and with GFP fluorescence greater than the predicted autofluorescence. Surprinsingly, exponential fits do not have higher r2 than linear fits. However, the distribution of slopes is narrower with the exponential model.

```{r}
p_decayfit_r2_ecdf <- ggplot(data = bleaching_fits) +
  facet_grid(condition~., margins=TRUE) +
  stat_ecdf(aes(r2, col='linear')) +
  stat_ecdf(aes(exp_r2, col='exponential')) +
  xlim(0, 1) +
  labs(col='fit', x='Pearson correlation decay fit', y='fraction cell cycles') +
  theme_classic() + 
  theme(legend.justification=c(0,1), legend.position=c(0, 1))


bleaching_fits %>% 
  gather(variable, value, r2, exp_r2) %>% 
  ggplot() +
  facet_grid(condition~variable, margins='condition') +
  geom_point(aes(fluogfp_amplitude_ini, value, col=variable), alpha=0.2, size=1) +
  # xlim(0, 1) +
  labs(col='fit', y='Pearson correlation decay fit') +
  theme_classic() # + theme(legend.position=c(0.2, 0.85))


# .bw <- .1
# ggplot(data = filter(bleaching_fits, r2>.8)) +
#   geom_step_hist(aes(slope/mean(slope), col='lin'), binwidth=.bw) +
#   geom_step_hist(aes(exp_slope/mean(exp_slope, na.rm=T), col='exp'), binwidth=.bw)

ggplot(data = filter(bleaching_fits, r2>.8)) +
  facet_grid(condition~., margins=TRUE) +
  stat_ecdf(aes(slope/mean(slope), col='lin')) +
  stat_ecdf(aes(exp_slope/mean(exp_slope, na.rm=T), col='exp')) +
  scale_x_continuous(trans='log2', limits=c(0.5, 2))

```

```{r eval=FALSE}
# estimation of GFP measurement errors from decay fits
bleaching_fits %>% 
  filter(exp_r2 > 0.8, condition !='switch_iptg') %>% 
  left_join(myframes) %>% 
  group_by(date, pos, gl, id) %>% 
  filter(medium=='glucose', m_cycle>1, time_sec>m_start+30*60) %>%
  mutate(time_sec_ini=first(time_sec),
         fluogfp_predict=mod_exp %>% first %>% predict %>% exp) %>% 
  filter(fluogfp_predict<5e4) %>% 
  # ungroup %>% sample_n(2000) %>%
  ggplot(aes(fluogfp_predict, ((fluogfp_amplitude-fluogfp_predict)/fluogfp_predict) %>% abs)) +
  # geom_point(size=.1, alpha=.2) +
  # stat_summary(aes(mycut(1/fluogfp_predict, seq(0, 2e-3, by=2e-5))), 
  stat_summary(aes(mycut(fluogfp_predict, seq(0, 1e5, by=1e3))),
               fun.data=mean_se, geom='pointrange', col='red') +
  labs(x='GFP level (AU)') + expand_limits(y=0)

bleaching_fits %>% 
  filter(exp_r2 > 0.8, condition !='switch_iptg') %>% 
  left_join(myframes) %>% 
  filter(medium=='glucose', m_cycle>1, time_sec>m_start+30*60) %>%
  group_by(date, pos, gl, id) %>% 
  mutate(time_sec_ini=first(time_sec)) %>% 
  mutate(fluogfp_predict=mod_exp %>% first %>% predict %>% exp,
         fluogfp_rel_err=(fluogfp_amplitude-fluogfp_predict)/fluogfp_predict) %>% 
  ungroup %>% 
  mutate(fluogfp_class=Hmisc::cut2(fluogfp_predict, seq(min(fluogfp_predict), max(fluogfp_predict), by=1000)) ) %>% 
  group_by(fluogfp_class) %>% 
  summarise(mean=mean(fluogfp_amplitude), sd=sd(fluogfp_amplitude), var=var(fluogfp_amplitude), cov=sd/mean, n=n()) %>% 
  ungroup %>% filter(mean<5e4) %>% 
  # ggplot(aes(1/mean, cov)) +
  ggplot(aes(mean, var)) +
  # geom_point() +
  geom_line(aes(alpha=n)) +
  scale_alpha_continuous(limits=c(10, NA), na.value=0) +
  labs(x='GFP level (AU)', alpha='sample size') +
  expand_limits(y=0)

```


This can be explained by the fact that each cell spans a relatively narrow range of fluorescence (where linear and exponential decay are comparable) during its cell cycle. Hence the quality of the fit is dominated by experimental errors rather than by the overall shape. Moreover the broader distribution of slopes with the linear model can be explained by the fact that the slope scales with the total fluorescence in the linear model while the decay rate doesn't.

```{r}
p_decayfit_lin <- ggplot(bleaching_fits, aes(fluogfp_amplitude_ini, slope)) +
  facet_grid(condition~., margins=TRUE) +
  geom_errorbar(aes(ymin=slope-slope.sd/sqrt(npoints), ymax=slope+slope.sd/sqrt(npoints)), col=brewer_cols[1], alpha=.2, size=.2) +
  geom_point(col=brewer_cols[1], alpha=.2, size=1) + 
  geom_line(stat='smooth', method='lm', se=FALSE, col='black', alpha=.5) +
  labs(x='GFP level at birth (AU)', y='decay slope (linear fit)') +
  theme_classic()

p_decayfit_exp <- ggplot(filter(bleaching_fits, exp_slope<1e-4), aes(fluogfp_amplitude_ini, exp_slope)) +
  facet_grid(condition~., margins=TRUE) +
  geom_errorbar(aes(ymin=exp_slope-exp_slope.sd/sqrt(npoints), ymax=exp_slope+exp_slope.sd/sqrt(npoints)), col=brewer_cols[2], alpha=.2, size=.2) +
  geom_point(col=brewer_cols[2], alpha=.2, size=1) + 
  stat_smooth(method='lm', se=FALSE, geom='line', col='black', alpha=.5) + # , aes(weight=(exp_slope.sd/sqrt(npoints))^(-2))
  scale_y_continuous(labels = comma) +
  labs(x='GFP level at birth (AU)', y='decay rate (exp. fit)') +
  theme_classic()

# pdf('plots/article/decay_gfp.pdf', width=10, height=3)
# grid.arrange(p_decayGFP_lin, p_decayGFP_exp, ncol=2)
# dev.off()

# pdf('plots/article/decay_fit.pdf', width=12, height=3)
# grid.arrange(p_decayfit_r2_ecdf, p_decayfit_lin, p_decayfit_exp, ncol=3)
# dev.off()

```

Although, it is appealing to take the slope errors into account in order to compute the average decay, this corresponds to a model in which each cell has the same true decay rate and errors are domintaed by experimental measurements; this is clearly not the case here (because the error bars are much smaller than the spread of the slopes distribution). Hence, we rather use a model in which the variance is dominated by the variance of the gaussian from which the slopes are drawn (hence assuming than the variance accounting for the measurement errors in each cell is small relative to this).

```{r}
bleaching_rate <- bleaching_fits %>%
  ungroup %>%
  # summarise(mean=-sqrt( sum(exp_slope^2/exp_slope.sd^2) / sum(1/exp_slope.sd^2) ), 
  #           sd=1 / sqrt(sum(1/exp_slope.sd^2)))
  summarise(mean=mean(exp_slope),
            sd=sqrt(var(exp_slope)/n()),
            mean_weighted=sum(exp_slope/exp_slope.sd^2) / sum(1/exp_slope.sd^2), 
            sd_weighted=1 / sqrt(sum(1/exp_slope.sd^2)) )

ggplot(data = bleaching_fits) +
  geom_histogram(aes(exp_slope), fill='gray35') +
  geom_vline(xintercept=bleaching_rate$mean) +
  labs(x='bleaching + decay rate (/s)')

p_decayfit_exp2 <- p_decayfit_exp +
  geom_hline(yintercept=bleaching_rate$mean, col=brewer_cols[2], lty='dashed')
# pdf('plots/article/decay_fit.pdf', width=12, height=3)
# grid.arrange(p_decayfit_r2_ecdf, p_decayfit_lin, p_decayfit_exp2, ncol=3)
# dev.off()

```



## GFP conversion factor estimation

For each division event (where mother and both daughters are observed for 10 frames or more; discarding bottom cell), we estimate the fluorescence and size at division. On one hand, we do it by average ing the last and first 3 frames around division; on the other hand, we do it by fitting the previously characterized exponential decay for the fluorescence and a free exponential growth for the size to the last and first 10 frames around division.

Reassuringly, while the daughters sum is systematically lower than their mother (due to bleaching + degradation) with the average estimation, the sum is closer to the mother value with the fit. In the following we assume these are equal and use the sum to compute the bias since this is less subject to measurement errors. Regarding the size estimation, the fit underestimate size at birth as already established by Erik.

```{r}
filter(myframes, !discard_start, !discard_top, condition=='switch_04h') %>% 
  filter(medium=='glucose', m_cycle>1, time_sec>=m_start+30*60, time_sec<=m_end-30*60) %>%
  filter(cell_num_in_lane < total_cell_in_lane) %>% # discard bottom cells
  # ungroup %>% filter(gl_id %in% nth(unique(gl_id), 10)) %>% # workaround a dplyr 0.5 bug
  ungroup %>% filter(gl_id %in% (unique(gl_id)[[10]]) ) %>%
  group_by(date, pos, gl, id) %>% 
  mutate(npoints=sum(fluogfp_amplitude>0)) %>%
  filter(npoints>10) %>%
  mutate(time_sec_ini=first(time_sec)) %>% 
  ggplot(aes(time_sec, fluogfp_amplitude, col=cell)) +
  geom_path(alpha=0.6) +
  expand_limits(y=0) +
  scale_colour_periodic_brewer(guide='none') +
  scale_x_hours(2) 

triad_avgw <- 3
triad_fitw <- 10
set.seed(19082328)
swi_triads <- filter(myframes, !discard_start, !discard_top, condition=='switch_04h') %>% 
  filter(medium=='glucose', m_cycle>1, time_sec>=m_start+30*60, time_sec<=m_end-30*60) %>%
  filter(cell_num_in_lane < total_cell_in_lane) %>% 
  # group_by(date, pos, gl) %>%
  partition(date, pos, gl,
            cluster=mycluster %>% cluster_assign_obj(dt) %>% cluster_assign_obj(bleaching_rate) %>%
              cluster_assign_obj(triad_avgw) %>% cluster_assign_obj(triad_fitw) %>%
              cluster_assign_func(autofluo_predict)) %>%
  do( (function(.df1){
    # first loop on all growth lanes
    filter(.df1, end_type=="div") %>%
      group_by(id, genealogy) %>%
      filter(mean(fluogfp_amplitude) > mean(autofluo_predict(length_um))) %>%
      do( (function(.df1, .dfp){
          # then loop on all cells
         .dfp <- mutate(.dfp, time_to_div = time_sec - (last(time_sec)+dt/2*60))
         if (sum(.dfp$fluogfp_amplitude>0) < max(triad_avgw, triad_fitw)) return(data.frame())
         .dfcb <- filter(.df1, parent_id==unique(.dfp$id), daughter_type=='BOTTOM') %>%
           mutate(time_from_birth = time_sec - (first(time_sec)-dt/2*60))
         if (sum(.dfcb$fluogfp_amplitude>0) < max(triad_avgw, triad_fitw)) return(data.frame())
         .dfct <- filter(.df1, parent_id==unique(.dfp$id), daughter_type=='TOP') %>%
           mutate(time_from_birth = time_sec - (first(time_sec)-dt/2*60))
         if (sum(.dfct$fluogfp_amplitude>0) < max(triad_avgw, triad_fitw)) return(data.frame())

         length_modp <- fastLmPure(cbind(1, .dfp$time_to_div), log(.dfp$length_um))
         .dfp <- mutate(.dfp, length_div = length_um / exp(length_modp$coefficients[2] * time_to_div),
                        fluogfp_div = fluogfp_amplitude / exp( bleaching_rate$mean * time_to_div))
         length_modcb <- fastLmPure(cbind(1, .dfcb$time_from_birth), log(.dfcb$length_um))
         .dfcb <- mutate(.dfcb, length_birth = length_um / exp(length_modcb$coefficients[2] * time_from_birth),
                         fluogfp_birth = fluogfp_amplitude / exp( bleaching_rate$mean * time_from_birth))
         length_modct <- fastLmPure(cbind(1, .dfct$time_from_birth), log(.dfct$length_um))
         .dfct <- mutate(.dfct, length_birth = length_um / exp(length_modct$coefficients[2] * time_from_birth),
                         fluogfp_birth = fluogfp_amplitude / exp( bleaching_rate$mean * time_from_birth))
         # browser()       
# #          qplot(time_to_div, fluogfp_div, data=.dfp, col='div') + geom_point(aes(y=fluogfp_amplitude, col='raw'))
#          ggplot(.dfcb, aes(time_from_birth, log(fluogfp_amplitude), col='raw')) +
#            geom_point() +
#            geom_point(aes(y=log(fluogfp_birth), col='birth')) +
#            geom_hline(aes(colour='birth'), yintercept=log(mean(.dfcb$fluogfp_birth))) +
#            stat_smooth(method='lm', se=FALSE, fullrange=TRUE) +
#            geom_abline(slope=bleaching_rate$mean, intercept=log(mean(.dfcb$fluogfp_birth)))
#          ggplot(.dfct, aes(time_from_birth, log(fluogfp_amplitude), col='raw')) +
#            geom_point() +
#            geom_point(aes(y=log(fluogfp_birth), col='birth')) +
#            geom_hline(aes(colour='birth'), yintercept=log(mean(.dfct$fluogfp_birth))) +
#            stat_smooth(method='lm', se=FALSE, fullrange=TRUE) +
#            geom_abline(slope=bleaching_rate$mean, intercept=log(mean(.dfct$fluogfp_birth)))
# #          qplot(time_from_birth, log(fluogfp_birth), data=.dfct, col='birth') + 
# #            geom_point(aes(y=log(fluogfp_amplitude), col='raw'))
         
         bind_cols(
           filter(.dfp, row_number() > dim(.dfp)[1] - triad_avgw) %>%
             select(end_time, length_avg=length_um, fluo_avg=fluogfp_amplitude) %>%
             summarise_each(funs(mean)) %>%
             mutate(div_time=unique(.dfp$end_time)+dt/2*60, n_fit=dim(.dfp)[1],
                    fluo_fit=mean(.dfp$fluogfp_div), fluo_fit_sd=sd(.dfp$fluogfp_div)*sqrt((n_fit-1)/n_fit),
                    length_fit=mean(.dfp$length_div), length_fit_sd=sd(.dfp$length_div)*sqrt((n_fit-1)/n_fit)),
           
           filter(.dfcb, row_number() <= triad_avgw) %>%
             group_by(id, genealogy) %>% select(length_avg=length_um, fluo_avg=fluogfp_amplitude) %>%
             summarise_each(funs(mean)) %>%
             # mutate(n_fit=dim(.dfcb)[1], pole=ifelse(str_detect(genealogy, "(?<=B)B$|(?<=T)T$"), "old", "new"),
             mutate(n_fit=dim(.dfcb)[1], pole=ifelse(str_detect(genealogy, "B{2,}$|T{2,}$"), "old", "new"),
                    fluo_fit=mean(.dfcb$fluogfp_birth), fluo_fit_sd=sd(.dfcb$fluogfp_birth)*sqrt((n_fit-1)/n_fit),
                    length_fit=mean(.dfcb$length_birth), length_fit_sd=sd(.dfcb$length_birth)*sqrt((n_fit-1)/n_fit)) %>%
             setNames(., paste("b", names(.), sep=".")),
           
           filter(.dfct, row_number() <= triad_avgw) %>%
             group_by(id, genealogy) %>% select(length_avg=length_um, fluo_avg=fluogfp_amplitude) %>%
             summarise_each(funs(mean)) %>%
             mutate(n_fit=dim(.dfct)[1], pole=ifelse(str_detect(genealogy, "B{2,}$|T{2,}$"), "old", "new"),
                    fluo_fit=mean(.dfct$fluogfp_birth), fluo_fit_sd=sd(.dfct$fluogfp_birth)*sqrt((n_fit-1)/n_fit),
                    length_fit=mean(.dfct$length_birth), length_fit_sd=sd(.dfct$length_birth)*sqrt((n_fit-1)/n_fit)) %>%
             setNames(., paste("t", names(.), sep="."))
         )
       })(.df1, .) )
  })(.) ) %>% 
  collect() %>% 
  # add convenience variables
  ungroup %>% 
  mutate(fbias_bottom=b.fluo_fit / (b.fluo_fit + t.fluo_fit),
         lbias_bottom=b.length_fit / (b.length_fit + t.length_fit),
         lbias_old=ifelse(b.pole=="old", lbias_bottom, 1-lbias_bottom),
         fbias_old=ifelse(b.pole=="old", fbias_bottom, 1-fbias_bottom),
         rnd=runif(dim(.)[1])<0.5, lbias_rnd=ifelse(rnd, lbias_bottom, 1-lbias_bottom),
         fbias_rnd=ifelse(rnd, fbias_bottom, 1-fbias_bottom) )

# write.csv(swi_triads %>% data.frame, file='nu_triads_20151230.csv')

ggplot(swi_triads) +
  geom_point(aes(fluo_avg, b.fluo_avg+t.fluo_avg, col='avg'), alpha=.5) +
  geom_errorbar(aes(fluo_fit, b.fluo_fit+t.fluo_fit, col='fit',
                    ymin=b.fluo_fit+t.fluo_fit - (b.fluo_fit_sd/sqrt(b.n_fit)+t.fluo_fit_sd/sqrt(t.n_fit)), 
                    ymax=b.fluo_fit+t.fluo_fit + (b.fluo_fit_sd/sqrt(b.n_fit)+t.fluo_fit_sd/sqrt(t.n_fit))), alpha=.5) +
  geom_point(aes(fluo_fit, b.fluo_fit+t.fluo_fit, col='fit'), alpha=.5) + 
  geom_abline() +
  labs(col='estimation')

ggplot(swi_triads) +
  geom_point(aes(length_avg, b.length_avg+t.length_avg, col='avg'), alpha=.5) +
  geom_point(aes(length_fit, b.length_fit+t.length_fit, col='fit'), alpha=.5) + 
  geom_abline() +
  labs(col='estimation')

```


```{r}
ggplot(data=swi_triads, aes(b.fluo_fit + t.fluo_fit , fbias_rnd)) +
  geom_hline(yintercept=0.5, lty='dashed') + 
  # stat_density2d(fill='blue', col='transparent', alpha=.05, geom='polygon') + # , binwidth=1e-4
  geom_point(alpha=0.5, size=1) + 
  ylim(0.35, .65) +
#   geom_pointrange(aes(x=fluo, y=m, ymin=m-s, ymax=m+s), 
#                   data=data.frame(fluo=seq(5e3, 4e4, 1e3)) %>% mutate(
#                     m=sapply(fluo, function(.fl) 
#                       filter(swi_triads, between(fluo_fit, .fl-1e3, .fl+1e3)) %>% mutate(bias=b.fluo_fit / (b.fluo_fit + t.fluo_fit)) %>% .[['bias']] %>% mean),
#                     s=sapply(fluo, function(.fl) 
#                       filter(swi_triads, between(fluo_fit, .fl-1e3, .fl+1e3)) %>% mutate(bias=b.fluo_fit / (b.fluo_fit + t.fluo_fit)) %>% .[['bias']] %>% sd)) ) +
  labs(x='total fluorescence (DN)', y='GFP bias toward daughter 1')
# ggsave('plots/asc_nutriads_fluotot.pdf', width=3.9, height=2.9)

ggplot(data=swi_triads, aes(lbias_rnd, fbias_rnd)) +
  geom_hline(yintercept=0.5, lty='dashed') + 
  geom_smooth(method='lm', se=TRUE) + 
  geom_point(alpha=0.5, size=1) + 
  xlim(0.42, 0.58) +
  labs(x='length bias toward daughter 1', y='GFP bias toward daughter 1') 
# ggsave('plots/asc_nutriads_length.pdf', width=3.9, height=2.9)

ggplot(swi_triads, aes(lbias_rnd, fbias_rnd-lbias_rnd)) +
  geom_hline(yintercept=0, lty='dashed') + 
  geom_smooth(method='lm', se=TRUE) + 
  geom_point(alpha=0.5, size=1) + 
  xlim(0.42, 0.58) +
  labs(x='volume bias toward daughter 1', y='volume-corrected \nGFP bias toward daughter 1') 
# ggsave('plots/asc_nutriads_lengthcor.pdf', width=3.9, height=2.9)

# # manually check the effect of random assignement on the r2
# swi_triads %>% ungroup %>% 
#   mutate(fbias_bottom=b.fluo_fit / (b.fluo_fit + t.fluo_fit),
#          lbias_bottom=b.length_fit / (b.length_fit + t.length_fit),
#                          rnd=runif(dim(.)[1])<0.5, lbias_rnd=ifelse(rnd, lbias_bottom, 1-lbias_bottom),
#                 fbias_rnd=ifelse(rnd, fbias_bottom, 1-fbias_bottom) ) %>% 
#   summarise(r2_lb_fb=cor(lbias_bottom, fbias_bottom, use="complete.obs", method="pearson")^2,
#             r2_lb_cfb=cor(lbias_bottom, fbias_bottom-lbias_bottom, use="complete.obs", method="pearson")^2,
#             r2_lr_fr=cor(lbias_rnd, fbias_rnd, use="complete.obs", method="pearson")^2,
#             r2_lr_cfr=cor(lbias_rnd, fbias_rnd-lbias_rnd, use="complete.obs", method="pearson")^2)

ggplot(swi_triads %>%
         # filter(between(b.fluo_fit + t.fluo_fit, 5e3, 3e4)) %>% 
         filter(b.fluo_fit + t.fluo_fit > 5e3) ) +
  geom_hline(yintercept=0, lty='dashed') +
#   stat_smooth(aes(b.fluo_fit+t.fluo_fit, fbias_rnd-lbias_rnd, col="random"), method="lm") +
#   geom_point(aes(b.fluo_fit+t.fluo_fit, fbias_rnd-lbias_rnd, col="random"), alpha=.5) +
  # geom_hline(aes(yintercept=mean(fbias_rnd-lbias_rnd), col="random")) +
  stat_smooth(aes(b.fluo_fit+t.fluo_fit, fbias_bottom-lbias_bottom, col="bottom"), method="lm", show.legend=FALSE) +
  geom_point(aes(b.fluo_fit+t.fluo_fit, fbias_bottom-lbias_bottom, col="bottom"), alpha=.5) +
  # geom_hline(aes(yintercept=mean(fbias_bottom-lbias_bottom), col="bottom")) +
  stat_smooth(aes(b.fluo_fit+t.fluo_fit, fbias_old-lbias_old, col="old"), method="lm", show.legend=FALSE) +
  geom_point(aes(b.fluo_fit+t.fluo_fit, fbias_old-lbias_old, col="old"), alpha=.5) +
  # geom_hline(aes(yintercept=mean(fbias_old-lbias_old), col="old")) +
  labs(x="mother's total GFP (molecules)", y="volume-corrected GFP bias", col="criteria") +
  theme(legend.justification=c(1,1), legend.position=c(1, 1)) +
  guides(col=guide_legend(override.aes = list(size=3, alpha=1)))
# ggsave('plots/asc_nutriads_oldpolebias.pdf', width=4, height=4)

# table(swi_triads$b.pole=="old")

```

For each triad, we can compute a conversion factor (cf Rosenfeld method 1).

```{r}
swi_triads <- swi_triads %>%
  mutate(nu=(b.fluo_fit - t.fluo_fit)^2 / ((b.fluo_fit + t.fluo_fit)),
         fluo_bin=Hmisc::cut2(fluo_fit, cuts=seq(0, 1e5, 5e3), oneval=FALSE)) # fluo_bin2=Hmisc::cut2(fluo_fit, g=7, oneval=FALSE)
nu_star <- mean(swi_triads$nu, na.rm=TRUE) # DN per FP
nu_err <- nu_star / sqrt(dim(swi_triads)[1])

```

or use Erik's method accounting for fluctuations in size.

```{r eval=FALSE}
partitioning_nosize_loglik <- function(.lambda, .v, .x, .y) {
  if (length(.x) != length(.y)) stop('.x and .y must have the same length')
  .a <- .v + 1 / (4*.lambda * (.x+.y))
  sum( - (.x/(.x+.y) -.5)^2 / .a - log(.a), na.rm=TRUE)
}
partitioning_nosize_loglik_wrapper <- function(.pars, .x, .y)
  partitioning_nosize_loglik(.pars[1], .pars[2], .x, .y)

partitioning_nosize_opt <- with(swi_triads,
                         optim(c(.1, 1e-4), partitioning_nosize_loglik_wrapper, control = list(fnscale = -1),
                               .x=swi_triads$b.fluo_fit, .y=swi_triads$t.fluo_fit) )
# if (partitioning_nosize_opt$convergence == 0) { fp_per_dn <- partitioning_nosize_opt$par[1]} else { rm('fp_per_dn') }

```


```{r}
partitioning_loglik <- function(.lambda, .v, .x, .y, .r) {
  if (length(.x) != length(.y) || length(.x) != length(.r)) stop('.x, .y and .r must have the same length')
  .a <- .v + (.r * (1-.r)) / (.lambda * (.x+.y))
  -sum( (.x/(.x+.y) - .r)^2 / .a + log(.a), na.rm=TRUE)
}
partitioning_loglik_wrapper <- function(.pars, .x, .y, .r)
  partitioning_loglik(.pars[1], .pars[2], .x, .y, .r)

partitioning_opt <- with(swi_triads,
                                  optim(c(.1, 1e-4), partitioning_loglik_wrapper, control = list(fnscale = -1),
                                   .x=b.fluo_fit, .y=t.fluo_fit, .r=b.length_fit/(b.length_fit+t.length_fit)) )
fp_per_oligomers <- 4 # lacZ is tetrameric
if (partitioning_opt$convergence == 0) { fp_per_dn <- partitioning_opt$par[1] * fp_per_oligomers} else { rm('fp_per_dn') }
if (use_eriks_params)
  fp_per_dn <- 0.0361 * fp_per_oligomers
```


```{r eval=FALSE}
# work in progress: hunting for the difference with Erik

with(swi_triads,
    partitioning_loglik(10^(-2.13), 10^(-2.67),
      .x=b.fluo_fit, .y=t.fluo_fit, .r=b.length_fit/(b.length_fit+t.length_fit)) )

# ls <- seq(1e-5, 1e-1, length.out=200)
# vs <- seq(1e-3, 1e0, length.out=200)
ls <- 10^seq(-3, -1, length.out=200)
vs <- 10^seq(-5, -2, length.out=200)

lls <- with(swi_triads,
            outer(ls, vs, Vectorize(partitioning_loglik, c('.lambda', '.v')),
                  .x=b.fluo_fit, .y=t.fluo_fit, .r=b.length_fit/(b.length_fit+t.length_fit)) )
contour(log10(ls), log10(vs), lls)
plot_ly(x=log10(ls), y=log10(vs), z=t(lls), type="surface") #, transpose=TRUE)


partitioning_opt <- with(swi_triads,
                                  optim(c(.1, 1e-4), partitioning_loglik_wrapper, control = list(fnscale = -1),
                                   .x=b.fluo_fit, .y=t.fluo_fit, .r=b.length_fit/(b.length_fit+t.length_fit)) )
```


This yields a conversion factor FP/DN at `r format(fp_per_dn, digits=2)`. The sd of the volume bias is infered to be `r sqrt(partitioning_opt$par[2]) %>% format(digits=2)` while it is measured at `r (swi_triads$b.length_fit / (swi_triads$b.length_fit+swi_triads$t.length_fit)) %>% sd %>% format(digits=2)`.


We can now look at how the fluorescence measurement convert to number of gfp molecules.

```{r}

myframes <- myframes %>%
  # convert to gfp units (after subtracting autofluorescence)
  mutate(gfp_nb = fluogfp_amplitude * fp_per_dn)

myframes %>% 
  filter(!discard_top, condition=='glucose') %>% 
  ungroup %>% sample_n(1e5) %>% 
  ggplot(aes(fluo_amplitude, gfp_nb)) +
  geom_point(alpha=0.1, size=0.1) +
  stat_density2d() +
  expand_limits(x=0)

# ggplot(data=myframes %>% filter(!discard_top, condition=='lactose', length_um<3) %>% ungroup %>% head(1e5),
#        aes(fluo_amplitude, gfp_nb)) +
#   geom_point(alpha=0.1) 
# 
# qplot(gfp_nb, data=myframes %>% filter(!discard_top, condition=='lactose', length_um<3), binwidth=50)
# qplot(length_um, gfp_nb, data=myframes %>% filter(!discard_top, condition=='lactose', length_um<3), alpha=I(.01))

```


